---
layout: post
title:  "Contextual Word Embedding Analysis"
info: "What linguistic properties are encoded in contextual word embeddings?"
tech: "conceptual framework, design studies, applications, evaluation studies"
demos: [
  {name: "Gender bias in BERT", pdf: "https://ieeexplore.ieee.org/abstract/document/9904461", link: "https://adapters.demo.lingvis.io", img: "assets/img/insights-bias.png", descr: "Visualizations can be used to compare models according to their word embedding spaces. By measuring the similarity between words in the modelâ€™s parameter space for specific concepts (e.g., stereotypical words and different gender), we can see associations that the models have learned from the training data."},
  {name: "Unexpected biases in BLOOM-1b3", pdf: "https://ieeexplore.ieee.org/abstract/document/10357717", link: "https://prompt-comparison.lingvis.io", img: "assets/img/insights-prompt-bias4.png", descr: "Visualizations can also be used to compare model outputs for slightly varying prompts. By representing outputs in a common 2D space and using clustering on output trajectories, we visually group similar outputs for exploration. As showcased here, especially models with fewer parameters produce more biased outputs."},
  {name: "Function word embeddings encode context information", pdf: "https://onlinelibrary.wiley.com/doi/full/10.1111/cgf.14541", link: "https://lmfingerprints.lingvis.io", img: "assets/img/insights-lmfing-function-word2.png", descr: "In BERT, function word embeddings have a low self-similarity, especially in the upper layers. It means that the embedding vectors change if these words are used in different contexts. Hence, embedding vectors do not capture only the word semantic meaning. In upper layers, the nearest neighbors of function words do not necessary have the same POS tag, but rather the neighbors are content words from the same sentence."},
  #"Visualizations can help to explore when the model encodes specific linguistic properties. In the early layers of BERT, token nearest neighbors have a high lexical and semantic similarity. In middle layers, BERT captures named entity categories and syntax, i.e., tokens are more similar to those that have the same previous or following POS tag. In upper layers, tokens within the same sentence become more similar to each other."},  
  {name: "BERT does not 'understand' function word meaning", pdf: "https://aclanthology.org/2022.coling-1.272/", link: "https://function-words.lingvis.io", img: "assets/img/insights-funct-words3.png", descr: "Although function words are highly contextualized, the model does not necessarily 'understand' their functional meaning in the sentence. In many cases, BERT makes semantically wrong predictions when varying used quantifiers, negations, and other function word classes."},

]
---