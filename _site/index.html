<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title></title>

  <!-- CSS -->
  <link rel="stylesheet" href="/ap/assets/css/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  
  <!-- Font Awesome -->
  <link rel="stylesheet" type="text/css" href="/ap/assets/css/fontawesome-all.min.css">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="16x16" href="/ap/assets/favicon.ico">

  <!-- Google Analytics -->
  

</head>


  <body>
    <nav class="nav">
      <div class="nav-container">
        <a href="/ap/">
          <h2 class="nav-title"></h2>
        </a>
        <!--ul>
          <li><a href="/ap/">About</a></li>
          <li><a href="/ap/portfolio/">Portfolio</a></li>
        </ul-->
    </div>
  </nav>

    <main>
      <div class="about">
  <div class="profile">
    <img class="selfie" alt="Rita Sevastjanova" src="assets/img/profile.jpg" />
    <div class="info">
      <div class="title">Rita Sevastjanova</div>
      <div class="description">I design interactive visualizations to support analysis of complex, high-dimensional data.</div>
    </div>
  </div>

  <div class="content">
    <h1 id="about-me">About Me</h1>
<p>My research interests are related to large language models (LLMs) and their embedding spaces. In particular, I have worked on different projects to understand which linguistic properties and biases get encoded in contextual word embeddings. Together with my collaborators, I have designed diverse visual analytics approaches that support the interactive investigation of patterns in these high-dimensional vectors.</p>

<!--p>My interests are not limited to language models, though. During my PhD, I  also explored active learning and visual interactive labeling methods for generating labeled datasets with as little human input as possible, the potential of integrating game elements into visual analytics applications to support user engagement, and other visual data analysis methods.
<br /></p-->

<!--h1 id="career">Career</h1-->
<p><b>2023-now</b>: PostDoc at the ETH Zürich, Interactive Visualization and Intelligence Augmentation Lab
<br />
<b>2017-2023</b>: PhD at the University of Konstanz, Data Analysis and Visualization Lab</p>

    <div class="post">
      <!--h2 class="post-title">Contextual Word Embedding Analysis</h2>
      <div class="post-line"></div>
      <p>I am working on different projects related to contextual word embedding analysis. Understanding embedding potentials and limitations can help us to make decisions, e.g., when to use embeddings in text analysis applications and, more specific, which model’s and layer’s embeddings to use for a particular task at hand.</p-->

        <div class="social-layer">
        <div class="social-icons">
          <ul>
            <section class="articles">

              <article>
                <div class="article-wrapper">
                  <a href="https://embedding-framework.lingvis.io" title=""></a>
                  <figure>
                    <img src="/ap/assets/img/framework.png" alt="" width="50%"/>
                  </figure>
                  <div class="article-body">
                    <h2>Conceptual Framework</h2>
                    <p>
                      What to consider when designing applications for word embedding contextualization tasks?
                    </p>
                  </div>
                </div>
              </article>

              <article>
                <div class="article-wrapper">
                  <a href="https://adapters.demo.lingvis.io" title=""></a>
                  <figure>
                    <img src="/ap/assets/img/adapters.png" alt="" width="50%"/>
                  </figure>
                  <div class="article-body">
                    <h2>Adapter Comparison</h2>
                    <p>
                      Which language models encode semantic concepts such as stereotypes or word sentiment?
                    </p>
                  </div>
                </div>
              </article>

              <article>
                <div class="article-wrapper">
                  <a href="https://lmfingerprints.lingvis.io" title=""></a>
                  <figure>
                    <img src="/ap/assets/img/lmfingerprints.png" alt="" width="50%"/>
                  </figure>
                  <div class="article-body">
                    <h2>Linguistic Properties</h2>
                    <p>
                      Which linguistic properties are encoded in embedding vectors in different model's layers?
                    </p>
                  </div>
                </div>
              </article>

              <article>
                <div class="article-wrapper">
                  <a href="https://function-words.lingvis.io" title=""></a>
                  <figure>
                    <img src="/ap/assets/img/function-words.png" alt="" width="50%"/>
                  </figure>
                  <div class="article-body">
                    <h2>Impact of Function Words</h2>
                    <p>
                      Do models 'understand' the linguistic functionality of function words?
                    </p>
                  </div>
                </div>
              </article>

              <article>
                <div class="article-wrapper">
                  <a href="https://prompt-comparison.lingvis.io" title=""></a>
                  <figure>
                    <img src="/ap/assets/img/prompt-comparison.png" alt="" width="50%"/>
                  </figure>
                  <div class="article-body">
                    <h2>Generated Text Comparison</h2>
                    <p>
                      How to effectively compare texts generated by two different models?
                    </p>
                  </div>
                </div>
              </article>

              <article>
                <div class="article-wrapper">
                  <a href="https://embeddings-explained.lingvis.io" title=""></a>
                  <figure>
                    <img src="/ap/assets/img/interlinked-projections.png" alt="" width="50%"/>
                  </figure>
                  <div class="article-body">
                    <h2>Token Self-Similarity</h2>
                    <p>
                      What are the reasons for strong embedding contextualization?
                    </p>
                  </div>
                </div>
              </article>

            </section>
          </ul>
        </div>
      </div>


      <h2>Selected Publications</h2>
      <div class="">
        <ul>

          <li>
            <span><b>Rita Sevastjanova</b>, Simon Vogelbacher, Andreas Spitz, Daniel Keim, and Mennatallah El-Assady. 2023. Visual Comparison of Text Sequences Generated by Large Language Models. <i>In 2023 IEEE Visualization in Data Science (VDS), IEEE, 11-20.</i></span>
            <a href="https://ieeexplore.ieee.org/abstract/document/10357717" title="">
    <span class="fa-stack fa">
      <i class="fa fa-file-pdf"></i>
    </span>
            </a>
          </li>

          <li>
            <span><b>Rita Sevastjanova</b> and Mennatallah El-Assady. 2023. WEC-Explainer: A Descriptive Framework. <i>In Exploring Research Opportunities for Natural Language, Text, and Data Visualization (NLVIZ) Workshop at IEEE VIS.</i></span>
            <a href="https://bib.dbvis.de/publications/view/1028" title="">
    <span class="fa-stack fa">
      <i class="fa fa-file-pdf"></i>
    </span>
            </a>
          </li>

          <li>
            <span><b>Rita Sevastjanova</b>, A Kalouli, Christin Beck, Hanna Hauptmann, and Mennatallah El-Assady. 2022. LMFingerprints: Visual explanations of language model embedding spaces through layerwise contextualization scores. <i>In Computer Graphics Forum, 295-307.</i></span>
            <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/cgf.14541" title="">
    <span class="fa-stack fa">
      <i class="fa fa-file-pdf"></i>
    </span>
            </a>
          </li>

          <li>
            <span><b>Rita Sevastjanova</b>, Eren Cakmak, Shauli Ravfogel, Ryan Cotterell, and Mennatallah El-Assady. 2022. Visual comparison of language model adaptation. <i>In IEEE Transactions on Visualization and Computer Graphics 29, 1, 1178-1188.</i></span>
            <a href="https://ieeexplore.ieee.org/abstract/document/9904461" title="">
    <span class="fa-stack fa">
      <i class="fa fa-file-pdf"></i>
    </span>
            </a>
          </li>

          <li>
            <span>Aikaterini-Lida Kalouli*, <b>Rita Sevastjanova</b>*, Christin Beck, and Maribel Romero. 2022. Negation, coordination, and quantifiers in contextualized language models. <i>In International Conference On Computational Linguistics (COLING)</i> (*equal contribution).</span>
            <a href="https://aclanthology.org/2022.coling-1.272/" title="">
    <span class="fa-stack fa">
      <i class="fa fa-file-pdf"></i>
    </span>
            </a>
          </li>

          <li>
            <span><b>Rita Sevastjanova</b> and Mennatallah El-Assady. 2022. Beware the Rationalization Trap! When Language Model Explainability diverges from our Mental Models of Language. <i>In Communication in Human-AI Interaction Workshop at IJCAI-ECAI'22.</i></span>
            <a href="https://bib.dbvis.de/publications/view/993" title="">
    <span class="fa-stack fa">
      <i class="fa fa-file-pdf"></i>
    </span>
            </a>
          </li>

          <li>
            <span><b>Rita Sevastjanova</b>, Aikaterini-Lida Kalouli, Christin Beck, Hanna Schäfer, and Mennatallah El-Assady. 2021. Explaining Contextualization in Language Models using Visual Analytics. <i>In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), Association for Computational Linguistics, 464-476.</i></span>
            <a href="https://aclanthology.org/2021.acl-long.39/" title="">
    <span class="fa-stack fa">
      <i class="fa fa-file-pdf"></i>
    </span>
            </a>
          </li>


        </ul>
      </div>

    </div>

    </br>
    <div class="social-layer">
      <div class="social-icons">
        <ul>
          
<li>
  <a href="mailto:rita.sevastjanova@inf.ethz.ch" title="email">
    <span class="fa-stack fa-lg">
      <i class="fa fa-circle fa-stack-2x"></i>
      <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
    </span>
  </a>
</li>





















<li>
  <a href="https://www.linkedin.com/in/rita-sevastjanova-29a308149/" title="Follow On LinkedIn">
    <span class="fa-stack fa-lg">
      <i class="fa fa-circle fa-stack-2x"></i>
      <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
    </span>
  </a>
</li>

















<li>
  <a href="https://twitter.com/RSevastjanova" title="Follow On Twitter" class="type">
    <span class="fa-stack fa-lg">
      <i class="fa fa-circle fa-stack-2x"></i>
      <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
    </span>
  </a>
</li>








        </ul>
      </div>
    </div>
  </div>
</div>

    </main>
    <footer>
      <span>
        &copy; <time datetime="2024-05-05 11:35:18 +0200">2024</time> Rita Sevastjanova. <a href="https://github.com/kssim/about-portfolio/">A.P</a> theme by kssim.
      </span>
    </footer>
  </body>
</html>
