---
layout: post
title:  "Contextual Word Embedding Analysis"
info: "What linguistic properties are encoded in contextual word embeddings?"
tech: "conceptual framework, design studies, applications, evaluation studies"
demos: [  {name: "LayerFlow", pdf: "https://arxiv.org/abs/2504.10504", link: "https://layerflow.ivia.ch", img: "assets/img/layerflow.png", descr: "How to communicate uncertainty in dimensionality reduction when used for word embedding analysis?"},
#        {name: "Conceptual Framework", pdf: "https://bib.dbvis.de/publications/view/1028", link: "https://embedding-framework.lingvis.io", img: "assets/img/framework.png", descr: "What to consider when designing applications for word embedding contextualization tasks?"},
        {name: "LMFingerprints", pdf: "https://onlinelibrary.wiley.com/doi/full/10.1111/cgf.14541", link: "https://lmfingerprints.lingvis.io", img: "assets/img/lmfingerprints.png", descr: "Which linguistic properties are encoded in embedding vectors in different model's layers?"},
        {name: "Adapters", pdf: "https://ieeexplore.ieee.org/abstract/document/9904461", link: "https://adapters.demo.lingvis.io", img: "assets/img/adapters.png", descr: "Which language models encode semantic concepts such as stereotypes or word sentiment?"},
        {name: "Impact of Function Words", pdf: "https://aclanthology.org/2022.coling-1.272/", link: "https://function-words.lingvis.io", img: "assets/img/function-words.png", descr: "Do models 'understand' the linguistic functionality of function words?"},
        {name: "Generated Text Comparison", pdf: "https://ieeexplore.ieee.org/abstract/document/10357717", link: "https://prompt-comparison.lingvis.io", img: "assets/img/prompt-comparison.png", descr: "How to effectively compare texts generated by two language models?"},
        {name: "Token Self-Similarity", pdf: "https://aclanthology.org/2021.acl-long.39/", link: "https://embeddings-explained.lingvis.io", img: "assets/img/interlinked-projections.png", descr: "What are the reasons for strong embedding contextualization?"}]
papers: [{pdf: "https://ieeexplore.ieee.org/abstract/document/10357717", text: "<b>Rita Sevastjanova</b>, Simon Vogelbacher, Andreas Spitz, Daniel Keim, and Mennatallah El-Assady. 2023. Visual Comparison of Text Sequences Generated by Large Language Models. <i>In 2023 IEEE Visualization in Data Science (VDS), IEEE, 11-20.</i>"},
  {pdf: "https://bib.dbvis.de/publications/view/1028", text: "<b>Rita Sevastjanova</b> and Mennatallah El-Assady. 2023. WEC-Explainer: A Descriptive Framework. <i>In Exploring Research Opportunities for Natural Language, Text, and Data Visualization (NLVIZ) Workshop at IEEE VIS.</i>"},
  {pdf: "https://onlinelibrary.wiley.com/doi/full/10.1111/cgf.14541", text: "<b>Rita Sevastjanova</b>, A Kalouli, Christin Beck, Hanna Hauptmann, and Mennatallah El-Assady. 2022. LMFingerprints: Visual explanations of language model embedding spaces through layerwise contextualization scores. <i>In Computer Graphics Forum, 295-307.</i>"},
  {pdf: "https://ieeexplore.ieee.org/abstract/document/9904461", text: "<b>Rita Sevastjanova</b>, Eren Cakmak, Shauli Ravfogel, Ryan Cotterell, and Mennatallah El-Assady. 2022. Visual comparison of language model adaptation. <i>In IEEE Transactions on Visualization and Computer Graphics 29, 1, 1178-1188.</i>"},
  {pdf: "https://aclanthology.org/2022.coling-1.272/", text: "Aikaterini-Lida Kalouli*, <b>Rita Sevastjanova</b>*, Christin Beck, and Maribel Romero. 2022. Negation, coordination, and quantifiers in contextualized language models. <i>In International Conference On Computational Linguistics (COLING)</i> (*equal contribution)."},
  {pdf: "https://bib.dbvis.de/publications/view/993", text: "<b>Rita Sevastjanova</b> and Mennatallah El-Assady. 2022. Beware the Rationalization Trap! When Language Model Explainability diverges from our Mental Models of Language. <i>In Communication in Human-AI Interaction Workshop at IJCAI-ECAI'22.</i>"},
  {pdf: "https://aclanthology.org/2021.acl-long.39/", text: "<b>Rita Sevastjanova</b>, Aikaterini-Lida Kalouli, Christin Beck, Hanna Sch√§fer, and Mennatallah El-Assady. 2021. Explaining Contextualization in Language Models using Visual Analytics. <i>In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), Association for Computational Linguistics, 464-476.</i>"}
]
---

I am working on different projects related to contextual word embedding analysis. Understanding embedding potentials and limitations can help us to make decisions, e.g., when to use embeddings in text analysis applications and, more specific, which model's and layer's embeddings to use for a particular task at hand.